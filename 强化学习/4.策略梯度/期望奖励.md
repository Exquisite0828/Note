公式解读：

左边: R̄\_θ  表示在参数为θ的策略下的期望奖励

中间: Σ R(τ)p\_θ(τ)

* R(τ):  轨迹τ的总奖励（回报）
* p\_θ(τ):  在策略θ下产生轨迹τ的概率
* 求和覆盖所有可能的轨迹

实际的意义：描述了在这种策略θ下，进行一次训练的期望奖励


实际应用举例：

假设一个简单的游戏：

* 奖励函数:  赢+1，输-1，平局0
* 回报:  某次具体游戏的结果，如+1
* 期望奖励:  在当前策略下，平均每局游戏的期望得分，如0.3
